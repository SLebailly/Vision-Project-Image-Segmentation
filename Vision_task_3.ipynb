{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Challenge Task\n",
    "\n",
    "### Simon Laurent Lebailly, 2549365, s9sileba@teams.uni-saarland.de\n",
    "### Christian Mathieu Schmidt, 2537621, s9cmscmi@teams.uni-saarland.de"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Preliminaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import libaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Use CUDA if possible"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Check if CUDA is available, if not use the CPU.\n",
    "train_on_GPU = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if train_on_GPU else 'cpu')\n",
    "\n",
    "if train_on_GPU:\n",
    "    print('CUDA available!')\n",
    "else:\n",
    "    print('CUDA not available!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = True\n",
    "validate = True\n",
    "evaluate = True\n",
    "\n",
    "batch_size = 4\n",
    "epochs = 1\n",
    "\n",
    "learning_rate = 0.0002"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import dataset Cityscapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "#Define normalization for dataset\n",
    "normalize = transforms.Normalize(\n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std = [0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "#Define transformation for train, validation and test dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,512)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "class TransformToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample_out = (sample*256).long()\n",
    "        return sample_out\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize((256,512)),\n",
    "    transforms.ToTensor(),\n",
    "    TransformToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "#Path of dataset\n",
    "root_path = 'C:/Users/chris/Documents/Cityscapes_dataset/Cityscapes'\n",
    "\n",
    "\n",
    "#Import dataset for training\n",
    "train_set = datasets.Cityscapes(root=root_path, split='train', mode='fine', target_type='semantic', transform=transform, target_transform=target_transform)\n",
    "quantity_train = len(train_set)\n",
    "print('Quantity training data: '+ str(quantity_train))\n",
    "\n",
    "#Prepare training dataset for NN\n",
    "train_loader = data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "#Import dataset for validation\n",
    "validation_set = datasets.Cityscapes(root=root_path, split='val', mode='fine', target_type='semantic', transform=transform, target_transform=target_transform)\n",
    "quantity_validation = len(validation_set)\n",
    "print('Quantity validation data: '+ str(quantity_validation))\n",
    "\n",
    "#Prepare validation dataset for NN\n",
    "validation_loader = data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "#Import dataset for testing\n",
    "test_set = datasets.Cityscapes(root=root_path, split='test', mode='fine', target_type='semantic', transform=transform, target_transform=target_transform)\n",
    "quantity_test = len(test_set)\n",
    "print('Quantity testing data: '+ str(quantity_test))\n",
    "\n",
    "#Prepare test dataset for NN\n",
    "test_loader = data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Printouts for testing train set\n",
    "\n",
    "#print(train_loader)\n",
    "#print(validation_loader)\n",
    "#print(test_loader)\n",
    "\n",
    "#Tensor to image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "img, segm = train_set[3]\n",
    "#print(img)\n",
    "print(segm)\n",
    "#segm_norm = segm\n",
    "#segm_norm = (torch.round(segm*256)-1).long()\n",
    "#print(segm_norm.size())\n",
    "#targ_min = 32\n",
    "#targ_max = 0\n",
    "#for b in range(0, 1):\n",
    "#    for r in range(0,256):\n",
    "#        for c in range(0,512):\n",
    "#            #if label_mask[b][r][c] >= 32:\n",
    "#                #print(\"First eval: \" + str(label_mask[b][r][c]) + \", \" + str(b) + \", \" + str(r) + \", \" + str(c))\n",
    "#            if segm_norm[b][r][c] > targ_max:\n",
    "#                targ_max = segm_norm[b][r][c]\n",
    "#            if segm_norm[b][r][c] < targ_min:\n",
    "#                targ_min = segm_norm[b][r][c]\n",
    "#print(\"targ_min: \" + str(targ_min))\n",
    "#print(\"targ_max: \" + str(targ_max))\n",
    "\n",
    "#segm_norm = (segm*8)/256\n",
    "#print(segm_norm)\n",
    "#print(img.size())\n",
    "imshow(torchvision.utils.make_grid(img))\n",
    "imshow(torchvision.utils.make_grid(segm))\n",
    "#print(segm)\n",
    "#segm.show()\n",
    "#print(type(train_set))\n",
    "#print(train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define R2U-Net model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "#Modified code from the source: https://github.com/LeeJunHyun/Image_Segmentation/blob/master/network.py\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(conv_block, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(up_conv, self).__init__()\n",
    "\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(ch_in,ch_out,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.up(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Recurrent_block(nn.Module):\n",
    "    def __init__(self, ch_out, t=2):\n",
    "        super(Recurrent_block, self).__init__()\n",
    "\n",
    "        self.t = t\n",
    "        self.ch_out = ch_out\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_out,ch_out,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        for i in range(self.t):\n",
    "\n",
    "            if i==0:\n",
    "                x1 = self.conv(x)\n",
    "\n",
    "            x1 = self.conv(x+x1)\n",
    "\n",
    "        return x1\n",
    "\n",
    "\n",
    "\n",
    "class RRCNN_block(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, t=2):\n",
    "        super(RRCNN_block, self).__init__()\n",
    "\n",
    "        self.RCNN = nn.Sequential(\n",
    "            Recurrent_block(ch_out,t=t),\n",
    "            Recurrent_block(ch_out,t=t)\n",
    "        )\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(ch_in,ch_out,kernel_size=(1,1),stride=(1,1),padding=(0,0))\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.Conv_1x1(x)\n",
    "        x1 = self.RCNN(x)\n",
    "\n",
    "        return x+x1\n",
    "\n",
    "\n",
    "\n",
    "class R2U_Net(nn.Module):\n",
    "    def __init__(self, img_ch=3, output_ch=34, t=2):\n",
    "        super(R2U_Net, self).__init__()\n",
    "\n",
    "        # Layers for down and up\n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "        # Layers for encoding\n",
    "        self.RRCNN1 = RRCNN_block(ch_in=img_ch, ch_out=64, t=t)\n",
    "        self.RRCNN2 = RRCNN_block(ch_in=64, ch_out=128, t=t)\n",
    "        self.RRCNN3 = RRCNN_block(ch_in=128, ch_out=256, t=t)\n",
    "        self.RRCNN4 = RRCNN_block(ch_in=256, ch_out=512, t=t)\n",
    "        self.RRCNN5 = RRCNN_block(ch_in=512, ch_out=1024, t=t)\n",
    "\n",
    "        # Layers for decoding\n",
    "        self.Up5 = up_conv(ch_in=1024, ch_out=512)\n",
    "        self.Up_RRCNN5 = RRCNN_block(ch_in=1024, ch_out=512,t=t)\n",
    "        self.Up4 = up_conv(ch_in=512, ch_out=256)\n",
    "        self.Up_RRCNN4 = RRCNN_block(ch_in=512, ch_out=256,t=t)\n",
    "        self.Up3 = up_conv(ch_in=256, ch_out=128)\n",
    "        self.Up_RRCNN3 = RRCNN_block(ch_in=256, ch_out=128,t=t)\n",
    "        self.Up2 = up_conv(ch_in=128, ch_out=64)\n",
    "        self.Up_RRCNN2 = RRCNN_block(ch_in=128, ch_out=64,t=t)\n",
    "\n",
    "        # Convolution for output layer\n",
    "        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n",
    "\n",
    "\n",
    "    def encoding_image(self, input):\n",
    "        \"\"\"Left side of U (encoding of input image).\n",
    "            @:param input image as tensor\n",
    "            @:return list with every step of encoding\n",
    "        \"\"\"\n",
    "        x1 = self.RRCNN1(input)\n",
    "        x1_out = self.Maxpool(x1)\n",
    "\n",
    "        x2 = self.RRCNN2(x1_out)\n",
    "        x2_out = self.Maxpool(x2)\n",
    "\n",
    "        x3 = self.RRCNN3(x2_out)\n",
    "        x3_out = self.Maxpool(x3)\n",
    "\n",
    "        x4 = self.RRCNN4(x3_out)\n",
    "        out = self.Maxpool(x4)\n",
    "\n",
    "        return x1, x2, x3, x4, out\n",
    "\n",
    "\n",
    "    def decoding_image(self, bottleneck, encoded_image):\n",
    "        \"\"\"Right side of U (decoding) + Concatenation with the left U.\n",
    "            @:param bottleneck of U-Net as tensor\n",
    "            @:param list with encoding steps\n",
    "            @:return decoded output tensor\n",
    "        \"\"\"\n",
    "        x5 = torch.cat((encoded_image[3], self.Up5(bottleneck)), dim=1)\n",
    "        x5_up = self.Up_RRCNN5(x5)\n",
    "\n",
    "        x4 = torch.cat((encoded_image[2], self.Up4(x5_up)), dim=1)\n",
    "        x4_up = self.Up_RRCNN4(x4)\n",
    "\n",
    "        x3 = torch.cat((encoded_image[1], self.Up3(x4_up)), dim=1)\n",
    "        x3_up = self.Up_RRCNN3(x3)\n",
    "\n",
    "        x2 = torch.cat((encoded_image[0], self.Up2(x3_up)), dim=1)\n",
    "        out = self.Up_RRCNN2(x2)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Encoding path\n",
    "        encoded_image = self.encoding_image(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.RRCNN5(encoded_image[4])\n",
    "\n",
    "        # Decoding + concat path\n",
    "        decoded_image = self.decoding_image(bottleneck, encoded_image)\n",
    "\n",
    "        # Final output convolution\n",
    "        out = self.Conv_1x1(decoded_image)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load model to device\n",
    "r2u_net = R2U_Net().to(device)\n",
    "print(r2u_net)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4) Loss and Optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# optimizer variable\n",
    "optimizer = torch.optim.Adam(r2u_net.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5) Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Definition train and validation loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "def train_model(epoch, train_loader):\n",
    "    trainloader_loop = tqdm(train_loader)\n",
    "    printrate = int(quantity_train/(batch_size*10))\n",
    "    train_loss = 0.0\n",
    "\n",
    "    #Set model mode to train\n",
    "    r2u_net.train()\n",
    "\n",
    "    #Iterate over all batches in train_loader\n",
    "    for i, batch in enumerate(trainloader_loop):\n",
    "        #Input Image for forward pass\n",
    "        input_image = batch[0].to(device)\n",
    "\n",
    "        #Label \"image\" for comparing with loss function\n",
    "        label_mask = batch[1].to(device)\n",
    "        label_mask = label_mask.squeeze(1)\n",
    "\n",
    "        #Forward propagation\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output_model = r2u_net(input_image)\n",
    "\n",
    "            loss = criterion(output_model, label_mask)\n",
    "\n",
    "            #Print with loss\n",
    "            train_loss += loss.item()\n",
    "            if i % printrate == 0:\n",
    "                print('[%d, %5d] train_loss: %.3f' % (epoch+1, i+1, loss.item()))\n",
    "\n",
    "        #Backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        #update tqdm\n",
    "        trainloader_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(\"Finished training!\")\n",
    "\n",
    "    #Calculate validation_loss\n",
    "    train_loss = train_loss/(quantity_train * batch_size)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "\n",
    "def validate_model(epoch, validation_loader):\n",
    "    validationloader_loop = tqdm(validation_loader)\n",
    "    printrate = int(quantity_validation/(batch_size*10))\n",
    "    validation_loss = 0.0\n",
    "\n",
    "    #Set model mode to evaluation\n",
    "    r2u_net.eval()\n",
    "\n",
    "    #Iterate over all batches in validation_loader\n",
    "    for i, batch in enumerate(validationloader_loop):\n",
    "        #Input Image for forward pass\n",
    "        input_image = batch[0].to(device)\n",
    "\n",
    "        #Label \"image\" for comparing with loss function\n",
    "        label_mask = batch[1].to(device)\n",
    "        label_mask = label_mask.squeeze(1)\n",
    "\n",
    "        #Forward propagation\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output_model = r2u_net(input_image)\n",
    "\n",
    "            loss = criterion(output_model, label_mask)\n",
    "\n",
    "            #Print with loss\n",
    "            validation_loss += loss.item()\n",
    "            if i % printrate == 0:\n",
    "                print('[%d, %5d] validation_loss: %.3f' % (epoch+1, i+1, loss.item()))\n",
    "\n",
    "        #update tqdm\n",
    "        validationloader_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(\"Finished validation!\")\n",
    "\n",
    "    #Calculate validation_loss\n",
    "    validation_loss = validation_loss/(quantity_validation * batch_size)\n",
    "\n",
    "    return validation_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training and validation of the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "#Configure scheduler for learning_rate\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=int(2 * (epochs/10)))\n",
    "\n",
    "#Load parameters\n",
    "if os.path.isfile('task_3_model_parameters.pt'):\n",
    "    r2u_net = torch.load('task_3_model_parameters.pt')\n",
    "\n",
    "#Statistical parameters\n",
    "train_loss = 0.0\n",
    "train_loss_history = []\n",
    "validation_loss = 0.0\n",
    "validation_loss_history = []\n",
    "learning_rate_history = []\n",
    "\n",
    "\n",
    "#Iterate over every epoch\n",
    "if train:\n",
    "    for epoch in range(epochs):\n",
    "        #Train model\n",
    "        train_loss = train_model(epoch, train_loader)\n",
    "        train_loss_history.append(train_loss)\n",
    "\n",
    "        #Validate model\n",
    "        if validate:\n",
    "            validation_loss = validate_model(epoch, validation_loader)\n",
    "            validation_loss_history.append(validation_loss)\n",
    "\n",
    "        #Learning rate history\n",
    "        learning_rate_history.append(learning_rate)\n",
    "\n",
    "        scheduler.step(validation_loss)\n",
    "        torch.save(r2u_net, 'task_3_model_parameters.pt')\n",
    "\n",
    "    print(\"Finished train model!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Print lists of mean losses and scheduled learning for every epoch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Train loss of every epoch: \" + str(train_loss_history))\n",
    "print(\"Validation loss of every epoch: \" + str(validation_loss_history))\n",
    "print(\"Learning rate of every epoch: \" + str(learning_rate_history))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6) Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def one_row(ground_truth, prediction):\n",
    "    truth = prediction.argmax(dim=1).view(1,-1)\n",
    "    truth = np.squeeze(truth.numpy())\n",
    "\n",
    "    pred = ground_truth.view(1,-1)\n",
    "    pred = np.squeeze(pred.numpy())\n",
    "\n",
    "    return truth.astype(float), pred.astype(float)\n",
    "\n",
    "\n",
    "def evaluate(ground_truth, predictions):\n",
    "    ground_truth2 = ground_truth.copy()\n",
    "    predictions2 = predictions.copy()\n",
    "\n",
    "    f1_score = 0\n",
    "    auc_score = 0\n",
    "    dice_coefficient = 0\n",
    "\n",
    "    listlen = min(len(ground_truth2),len(predictions2))\n",
    "\n",
    "    for l in range(0, listlen):\n",
    "        x = ground_truth2[l]\n",
    "        y = predictions2[l]\n",
    "\n",
    "        transform_tensors = one_row(x, y)\n",
    "\n",
    "        f1_score += metrics.f1_score(transform_tensors[0], transform_tensors[1],average=None)\n",
    "        auc_score += metrics.roc_auc_score(transform_tensors[0], transform_tensors[1], average=None, multi_class='ovo')\n",
    "        dice_coefficient += abs(spatial.distance.dice(transform_tensors[0], transform_tensors[1], w=None))\n",
    "\n",
    "    f1_score = f1_score/listlen\n",
    "    auc_score = auc_score/listlen\n",
    "    dice_coefficient = dice_coefficient/listlen\n",
    "\n",
    "    return f1_score, auc_score, dice_coefficient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f1_score = -1000.0\n",
    "auc_score = -1000.0\n",
    "dice_coefficient = -1000.0\n",
    "\n",
    "truth_list = []\n",
    "pred_list = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Only during the programming. We dont want want to build the testlist every time\n",
    "breaker = True\n",
    "\n",
    "if evaluate:\n",
    "    testloader_loop = tqdm(test_loader)\n",
    "\n",
    "    #Set model mode to evaluation\n",
    "    r2u_net.eval()\n",
    "\n",
    "    #Iterate over all batches in validation_loader\n",
    "    for i, batch in enumerate(testloader_loop):\n",
    "        if breaker and i > 2:\n",
    "            break\n",
    "        #Input Image for forward pass\n",
    "        test_image = batch[0].to(device)\n",
    "\n",
    "        #Label \"image\" for comparing with loss function\n",
    "        ground_truth = batch[1].cpu()\n",
    "        ground_truth = ground_truth.squeeze(1)\n",
    "\n",
    "        #Forward propagation\n",
    "        with torch.cuda.amp.autocast():\n",
    "            prediction = r2u_net(test_image)\n",
    "\n",
    "        truth_list.append(ground_truth.float())\n",
    "        pred_list.append(prediction.cpu().float())\n",
    "\n",
    "    scores = evaluate(truth_list, pred_list)\n",
    "\n",
    "    f1_score = scores[0]\n",
    "    auc_score = scores[1]\n",
    "    dice_coefficient = scores[2]\n",
    "\n",
    "    print(\"Finished evaluation!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Print lists of scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"F1 score: \" + str(f1_score))\n",
    "print(\"AUC score: \" + str(auc_score))\n",
    "print(\"DICE coefficient: \" + str(dice_coefficient))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}